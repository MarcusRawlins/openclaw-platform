Transcript:
I've used OpenClaw every day, all day
for the past month, and I've gotten
extremely good at it. I've released a
number of OpenClaw use case videos, but
in this one, I am taking it to another
level. OpenClaw is now a full-time
employee on my team. So, let's get into
it. So, I get a lot of sponsorship
requests, companies who are emailing me
asking me to sponsor my videos, which is
fantastic, but I do get a lot of them.
So, I gave my OpenClaw its own identity
with a first name and last name, its own
email address, basically an entire
workspace account, so it looks
completely legit. It is now basically a
full-time employee for me. I have a
public-f facing sponsorship email
address that everybody can see. It's a
group email address, and I have added
OpenClause email to that. So, anybody
who's emailing that public-f facing
email address, those emails will now get
routed to my OpenClaw. and what I do
with it is absolutely wild. So, here's
an example email. This is not an actual
sponsor email. I didn't want to share
that publicly. This is just one that I
created and sent to my OpenClaus email
address. Hi, Madam Sarah, head of
partnerships at Novabbridge. We build
workflow automation tools for teams.
Okay, then we sign off. Novabbridge.io
is not a real email. And so, what
happened? Well, as you can see right up
here, my OpenClaw identified that it is
a sponsorship email and labeled it as
such and actually used a very
sophisticated rubric to score the email.
And so it scores it low, medium, high,
and exceptional. If it's exceptional,
which is, I believe, 80 or higher, it
doesn't do anything. It simply escalates
it to my team. And so it scored this one
a 38. And in fact, it wasn't actually
sure how to score it because it had some
weird signals. Obviously, it's coming
from my personal email address, so it
didn't really understand what to do with
that. Also, I forgot to remove my
signature from the email, so it signs
off as Sarah Chen, and then it also
signs off as Matthew Burman. And when it
doesn't have a high confidence about how
to score something, something special
happens. It pings me in Telegram. So,
this is what that looks like. Low
confidence classification for review.
The sender is me. Confidence score is
45. Very low. And it's guessing it
should be a 38 score. And so here are
the reasons. Sender uses a public Gmail
inbox. Email appears to be sent from
Matt's own Gmail. Nova bridge is an
unknown company with no verifiable web
presence or social proof. And so yes, it
actually goes out. It looks at the
website, looks if it's legit, finds
reviews of the company, looks up the
people at the company. It does this
entire research all in a couple minutes
and then applies the score. So that's
what we see here. Claims company email
and signature but sent from Gmail. No
budget deliverables. Series A claim is
unverifiable. And so what I can do from
here is just reply back saying approve.
You got it right. Or I can give it
feedback about how to score the email.
And I built the rubric over a few days.
It is not plugandplay. I would let it
assign a score, figure out how I felt
about the score, and then give it
feedback about that rubric. So, here's a
quick overview of what that rubric looks
like. We have five different main
dimensions: fit, clarity, budget,
seriousness, company trust, and close
likelihood. And they are all weighted
with a certain score and then when they
are scored, we can take different
actions. So, if it is an exceptional
company, it escalates to our team,
notifies us in Slack, doesn't do
anything else. No automated actions,
just tell us about it. If it's a high
sponsor, it escalates to the team, but
it isn't urgent, so we can get to it
when we can. For medium, we reply with
our qualification questions. For low, we
politely decline. And for spam, we just
ignore it. After it scores it, it will
actually draft a custom email back to
this person. And so that's what you're
seeing here. So it says, "Hey, Matthew."
And it says, "Hey, Matthew." Cuz I
signed off as Matthew accidentally.
Thanks for reaching out. Check out our
sponsorship options here. Let us know if
you have any questions at all. Best. And
then it's name. Then I simply come in
here. When I'm ready, I hit send and it
does everything else for me. It's so
easy. And if you want to recreate this
yourself, you absolutely can. Here's the
prompt for it. Build a sponsor inbox
pipeline. Multi-count email marketing
per account config JSON cron every 10
minutes go CLI for Gmail access lazy
backfill fetch historical threads for
new sender domains quarantine and
security and again I'm going to get to
my overall security best practices in a
moment then we score it with an editable
rubric. This means I am constantly
giving it feedback. It is constantly
getting better at scoring inbound
emails. We apply Gmail labels. We have
stage tracking both locally and in
HubSpot. We have contextaware reply
drafting. So, not just sending a
template email. Of course, we use one of
the best models for this, Opus 4.6. And
we also use the humanizer skill. We do
not want it to smell like AI writing.
Then we do sender research. We actually
go out, we look up who the company is,
who the sponsor is, we find out if it's
relevant, we find out if it's
legitimate. It does that all for me and
then pulls it into our CRM. And of
course, we have escalation at the very
end. So, I'm going to drop all the
prompts down below in the description.
Feel free to get them. And as I
mentioned, my entire team uses HubSpot
to track our sales. And OpenClaw has
access to HubSpot has access to move
deals around as it sees fit. So, it'll
automatically detect based on our email
conversations when a deal has moved
stages. Let's say from qualified to
negotiations, will send me a message
about it, update the team, and then move
the deal in HubSpot. All of this happens
automatically and HubSpot has been
phenomenal and they're also the partner
of this video. So, I know a lot of you
want to recreate a lot of what I've
done. And not only that, you probably
want to come up with use cases that are
very specific to your life or your
business. And a lot of you are
entrepreneurs and tinkers and trying to
figure out how to do that. And so, as AI
gets better and better, you need to stay
ahead. So, if you want to start actually
building with AI, not just seeing what
other people are doing, I suggest you
check out this free guide, 20 AI apps
that you can vibe code in a weekend.
This is the guide for turning scrappy AI
ideas into real working prototypes fast.
It breaks down practical app concepts,
how to scope them correctly, and how to
move from idea to MVP very quickly. And
all of this applies to OpenClaw.
OpenClaw is basically just vibe coding.
Personally, I found the section about
business and productivity AI apps
especially relevant to OpenClaw because
they show you concrete examples of
realworld automations that you can use
right now and they walk through how to
go from just a blank page to a fully
functioning app very quickly. So, this
guide was made by HubSpot. They're
sponsoring this video. Huge shout out to
HubSpot. They've been a fantastic
partner. Go download that ebook because
it helps us out, allows us to make more
cool videos like this. So big shout out
to them. All right. So finally you have
the prompt. You have the explanation of
what it does. Let me show you the
workflow from a high level. So first we
ingest from three different email
accounts. One of which is active. That
is the one that I assigned to my
openclaw agent. Then we refresh every 10
minutes. We quarantine and Frontier scan
it. So what does that mean? And I'm
going to go over more about the security
later, but let me just briefly tell you
what that means. The first thing it does
is scan the email with deterministic
code to figure out if there's any prompt
injections or SQL injections. Obviously,
it's not perfect, but that is just the
first layer. Then it downloads the
email. We quarantine it. We put it in
its own isolated place so it doesn't
have access to anything else going on.
Then we do something called Frontier
Scan. We take the best possible model
after we've already stripped it of
potentially malicious prompt injections
and we have it do another scan of it
again in quarantine. Once all of that is
done and it has a high confidence that
there is nothing malicious in that
email, then we score and classify it. It
reads the email, looks at previous
emails in our database from that same
person, looks at the rubric, puts it all
together, and comes up with a single
score. Then if necessary, we update the
HubSpot stage and we sync it. We look
for drift detection. So let's say the
deal in HubSpot moved, but we don't know
about it. We look and we'll notify our
team if we have a different record of
the stage than HubSpot does. Then we
apply Gmail labels. So that is a score
or a stage. Then we look if it's high
signal, we escalate to Telegram. We
store and embed the email locally. Then
we write a draft that is contextaware.
It is so useful and I did this
progressively. I didn't create this in
one go. I've slowly given it more and
more authority, more and more permission
to be automated from end to end. And
there's still so much more to do. I
actually have a vision where my open
clock can actually handle the sales
pipeline all the way up until the point
that a sponsor wants to get on a call
with us or I'm ready to make a video
about them. All right. Next, I want to
talk about a bunch of best practices.
Okay. So the first thing I want to tell
you about is multiple prompt versions.
This is actually more important than
probably most of you realize and
something that I've not seen many people
talk about. It is very complex to
manage, but it is critical. So I highly
recommend you do it. The problem is that
when you're using multiple models or you
switch models, let's say you're using
Opus 4.6 and your O token gets banned
and you want to move to GPT 5.2. Well,
those different models have different
prompting standards for how you should
prompt them. So I actually downloaded
Claude's best practices especially for
Opus 4.6 which is quite different from
previous versions and I have documented
everything locally. So here it is core
principles for example Opus does not
like using all caps like this critical
just tell it what to do. It really is
overindexing on following your
instructions. So you don't need to yell
at it or do anything like that. So I
download this whole thing and anytime
that I write a prompt I follow this
guide. But GPT 5.2 2 is different. It
uses very different prompting
techniques. So, of course, I downloaded
the GPT 5.2 prompting guide and it is
completely different and it has all of
the guides here. All caps. So, it's
literally the opposite. All caps is very
welcome. But that causes some problems.
How do you manage two sets of prompts
for everything? Well, I basically just
do it. I told my OpenClaw that I want to
have two versions of the prompts. I have
what's in the root. So, that's what
you're seeing here. This is optimized
for cloud. That is still my go-to model
and I will explain how I got around the
OOTH ban issue. So I have all of my
markdown files, not just these, all of
them optimized for Claude. Then I have a
separate folder for codeex optimized
prompts and this is all the same files
and every single night I have a nightly
sync review and it goes through all of
the markdowns. It looks at both of the
prompting best practices and makes sure
not only that each of them independently
are using the best practices, but that
they are not seeing drift, that they
don't say different things. The core
information in all of these markdown
files stays the same. And if there is
drift, I get a telegram alert in the
morning and all I have to do is say,
"Fix it." And it does. And that is how
it all stays in sync. So the longest
these files would ever be out of sync is
about 24 hours. So I highly recommend
you do this. You will get such better
results just by prompting it better.
This is prompt engineering 101. So
here's the prompt for that. Set up dual
prompt stacks. Root MD files claude
optimize natural language explain why
behind the rules. And you can also say
reference this specific guide that I've
downloaded. Then codeex prompts or
whatever other models you want.
Basically create a folder have all of
the same files across them. Give it some
of those best practices. But again,
probably just point to the prompt guide
that you downloaded. Both stacks must
contain identical operational facts,
nightly sync review, swap commands for
switching active model. That is the last
important part. I have instructions
about exactly how to swap the models. So
if I want to swap the models, it swaps
the name everywhere. It automatically
makes whatever folder that the secondary
model is in, it promotes that to being
in the root. it saves the other one in a
folder and it just has all the
instructions so I don't really have to
think about how to swap the models. I
just say swap the model and it does it.
All right, this is going to be more of a
basic section. I want to tell you about
what all the files in OpenClaw do and
how you should be using them. So for
agents.md
that is operational rules, security,
safety, task execution, message
patterns, cron standards, error
reporting and there's a reason I am
telling you about all this. You should
create a document so that your open claw
always knows where to put things and
you're not going to see prompt drift.
You don't want certain information
ending up in the wrong prompt file. And
then so we have both what belongs here
and what doesn't belong here. So we have
the soul file that's the personal
philosophy who the agent is. We have
identity name creature type emoji 5 to
10 lines max. This is all from the best
practices of openclaws documentation. We
have user.md basically telling openclaw
about myself. We have tools. These are
environment specific values. So channel
ids, slack ids, asauna project ids, etc.
We have the heartbeat which is a
periodic cron that runs automatically.
We have the memory.md file which only
should be loaded with me. It's not going
to be shared publicly at all including
with my team. We have the sub aent
policy, how to spin up sub aents, what
model to use, etc. And these are the
documents that get loaded only when
necessary, not in every single call. So
we have the PRD. This is incredibly
important. This defines all of the
functionality that I have across the
entire app. Really useful to give your
open claw a head start to know where to
look for certain pieces of code. We have
our use cases. We have our workspace
files, security best practices, coding
standards, memory files, skill files,
and reference files. So, we try to aim
for no duplication across files. There
should be one place to house every piece
of information, and that is defined
here. I'm not going to read this prompt.
I will drop it down below. Feel free to
grab it. All right. Next. I've already
talked about this, so I'm just going to
talk about it briefly, but if you're not
already using Telegram groups with
topics, you really should be. It is the
best way to optimize your context to
optimize your memory, and to just make
it easier on yourself. Here's what it
looks like for me. I have general, I
have a CRM topic, a knowledgebased
topic, cron updates, self-improvement,
daily brief, self-update, earnings,
forward future analysis, food journal,
video research. Basically, everything
that I'm doing with it has its own
channel so that it always has its own
context and you don't need to actually
reset the context of each of these
channels so frequently. So, it'll
remember more effectively. Okay, now I
have expanded the CRM functionality and
it is incredible. I talked about it in
the last video, but now it is just such
a killer feature. And it directly ties
to all of the work I did to give
OpenClaw its own email address and to
behave as a full employee. So, here's
what this CRM system looks like
currently. It scans Gmail for me, looks
for all important contacts that I'm
talking to, scans my calendar, does
contact discovery, so it filters out
spam, filters out marketing, filters out
event invites, everything. And it
classifies it all. It rejects most of
them. I think I only have 250 contacts
in my database right now. Most are just
rejected. Once it classifies it, it puts
it in my CRM database. So now I have a
record of not only who that person is,
but everything that I've talked to them
about. It does proactive research about
their company. So if there's a new
article or new piece of news that comes
out about that company, it automatically
finds it, downloads it, saves it all in
a local database, and of course, it
backs up that database and all
databases. Then from there, and this is
really the magic of OpenClaw, and I
don't think anybody is using it to this
level. When you have all of this
information, when you have a CRM, and
when you scan your emails and calendar
and Slack messages, a knowledge base,
once you have all of that, Open Claw
will start to make connections that you
didn't even think were possible. So, for
example, if it sees a new email from a
potential sponsor, it can reference
previous conversations that I've had
about companies that are similar. It can
look for any knowledgebased articles
about that company and it puts it all
together for me automatically. So once
it's in the CRM, I can do natural
language queries against it. Who have I
talked to in the last week? Who haven't
I talked to in the last four months?
Then it can provide automatic follow-ups
for me, nudges, summaries. It is
incredibly valuable. But like I said,
the real value is tying all the
different pieces together. The full-time
employee sales agent, the CRM, the
knowledge base, everything is tied
together now. And it is so incredibly
smart. It has context of my entire
business at all times and really allows
me and it to make better decisions. And
here's the full prompt. Contact
discovery pipeline, database, natural
language interface, relationship
intelligence, daily cron, and email
draft system. And for the database, we
use the same pattern for everything we
store locally. We have a traditional SQL
database with a vector column. So, we
can do SQL queries and we can also do
natural language queries like you would
with any rag system. All right, next is
meeting intelligence. I talked about
this briefly in the previous video, but
it has gotten so much better now. And
again, it just ties everything together.
Everything gets stored in the CRM.
HubSpot gets updated when necessary.
It's so cool. Check this out. We have a
meeting. I use a Fathom notetaker in my
meeting. So, it is automatically
transcribing every single meeting, both
internal and external. Then we check the
calendar and we pull the Fathom API
after a meeting ends and we download the
transcript. We match the attendees to
the CRM. We extract the insight. So not
just insights, but we also look for
action items. Then we generate the
context and embeddings. By the way, I am
now doing embeddings completely locally
using the Nomic embedding model. Then we
decide if there are action items. If
none, we're done. If yes, we send all
the action items to Telegram for my
approval because I don't want my to-do
list getting cluttered up. And if it is,
it goes to my to-doist, but now it also
goes to HubSpot. It doesn't say that
here, but it does. And so for any
meeting, we have an internal sales
meeting with three of us. It will
automatically know who is responsible
for each action item and will associate
it to the correct deal in HubSpot and
assign it automatically to the right
person. And it does so flawlessly. It is
so good. All right. Next is the
knowledge base. This is basically where
I throw everything that I want saved for
later. Articles, videos, exposts,
anything that I come across that I find
interesting, I throw it into Telegram.
So, here it is. Here's Gokal Rajarum and
saved. And it also gives me a little
summary and a little opinion on it.
Here's a reply post to that Catrini
research article that went viral
yesterday. also gave me some information
and found the Saturni article and linked
it to that automatically. And every time
it does it, it also shares it with my
team. So, here's what that looks like.
It shares it in the AI trends channel
and it just says, "Matt wants you to see
it because I don't want them to think
that I'm not reading these." I
absolutely am. So, it shares it there.
Then, if somebody on my team shares an
article, I just comment on it saying,
"Aclaude, put this in the knowledge
base." And it downloads it and does the
same thing. and it knows not to cross
post it back because somebody else
shared it. Then of course tying it all
together, whenever I have a contact in
the CRM, it looks for any articles about
them or their company. It also
proactively does that. So every single
day we're looking for new articles about
any of the companies we work with.
Automatically saves it to the knowledge
base. Here's the prompt. You can build
it yourself. This is one of the most
valuable things I have. Not just because
of the cross-pollination, but because I
can simply query against it. One of the
use cases I also use OpenClaw for is
coming up with video ideas and actually
writing outlines for me. And of course,
it references the knowledge base and
pulls any relevant articles to include
in my video topic. And so here's the
architecture of it. So we have either
Telegram knowledgebased topic or a Slack
save command does a pre-flight check
fetches the content. And of course I
have standardized the security
practices. Anytime I'm ingesting any
text from the internet, we sanitize it.
We put it in a sandbox. We do the
frontier scan on it. And if it's not
safe, we block it and we log the reason.
If it is safe, we continue. We chunk and
embed it. We store it in SQite, crossost
to AI trends, and then we can do
querying, semantic search, and get the
results plus the sources. It is so
awesome. Speaking of the content
pipeline, let me briefly talk about
that. So, anytime that I mention this is
a potential video idea, Claude will
automatically get to work. It reads the
full Slack thread for the context,
understands what we were talking about.
So, for example, if my team and I are
discussing a specific AI topic, we'll go
back and forth, and then I will simply
tag Claude on the thread and say
potential video idea. Then, it reads the
full Slack thread context, queries the
knowledge base for related content,
searches X and Twitter for supplementary
discourse, basically searches the web,
searches X, and looks for viral posts
about this topic. It creates a
structured ASA card. So, of course, it's
plugged into a sauna and it creates it
in the video pipeline project. Then, it
writes an outline for me, gives me
reference material for it. It's actually
really good. It also comes up with
packaging ideas. So, what's the hook?
What's the thumbnail? What's the title?
It does all of that. Gives me a bunch of
suggestions. And then finally, post back
to Slack or Telegram letting me know
it's done. All right, let's talk about
security. I've already touched on it,
but it's such an important topic. I
really want to go a little bit deeper
into it. There are multiple layers of
security that I've implemented at this
point. So, first we have layer 1 network
gateway hardening. This is all stuff
that either OpenClaw has built in
directly or my security council which
runs every night scanning everything in
OpenClaw looking for potential attack
vectors. Recommended tokenbased
authentication never exposed directly to
the internet weekly verification via
heartbeat. But we also, as I mentioned,
have a nightly security council that I
will go over in a moment. We have
channel access control. So, if it's a DM
with me, it can basically tell me any of
the information, but if it's in a Slack
group channel, it cannot. It redacts
information and it has a very strict
policy about what can be shared and what
can't. And of course, if it's writing
emails for me, it has an even stricter
policy. Then, we have a threelayer
prompt injection defense. This is
probably the thing that I am most
concerned about is somebody just trying
to prompt inject into one of the places
that we ingest data from the internet.
So we have a deterministic sanitizer
first. It is looking for things like
ignore previous instructions and other
things that I'm not going to list here
because I don't want to give away what
we're looking for. Then we have
something called a frontier scanner. It
is taking the best Frontier model. It
puts that data from the internet into a
sandbox. then takes that Frontier
scanner and scans it. That scanner
cannot do anything. The worst that could
happen is the Frontier model reveals
information that it already knows that
it's not supposed to say, like how to
hack a computer. Then we also have
elevated risk markers and it kind of
gives it a score along the way. Then we
also have secret protection. So outbound
redaction on all message paths and we
redact secrets. We redact PII as well,
personally identifiable information.
This is all deterministic. We really
don't want to take any chances with our
sensitive info. We have a pre-commit
hook that blocks common key patterns
from git. And we have our file
permissions locked down. We have
multiple layers of automated reviews of
our security. We have a nightly security
council that looks for file permissions,
gateway configs, secrets, etc. We have a
security council, offensive, defensive,
data privacy and operational realism. We
have cron health checks. We have system
health checks. Then we have data
permission last. We have encrypted
databases only. When we back up those
databases, we have passwords. So you
cannot get to them even if you know
where they are. We have data
classification tiers enforced on the per
conversation context. Of course, we have
SSRF prevention. We have SQL injection
protection. And all of this can be done
with this prompt right here, which I
will share. And so here is what that
security architecture looks like. I'm
not going to go over it cuz that's what
we just did. But this is generally what
that architecture looks like. All right,
next. Cron jobs. Chron jobs just means
scheduled things to do. It is really a
huge part of what I do with OpenClaw.
And I have a ton of scheduled jobs. And
not only are they scheduled, but it's
important to know when to schedule them.
So, I'm sure a lot of you have limited
quota as I do in terms of how many
tokens you get. So, you really want to
spread out those heavy cron jobs
throughout the night. So, for example,
at 1:00 a.m. we do our Instagram
analytics collection. At 1:15 we do X
and Twitter analytics collection. 1:30
is YouTube. 2 AM's the CRM. 3:20 and so
on all through the night. This is all
the stuff that can run asynchronously. I
don't have to keep an eye on it. I do
want it updated daily and it runs
overnight when I'm not using OpenClaw.
So if I'm heavily using OpenClaw during
the day and I run out of my quota, I
won't also go to do some of these cron
jobs that will waste even more quota.
It's spread out throughout the day. And
this is important when you have a 5hour
window, which you do if you're using
your cloud subscription. And if you're
wondering how I'm using my cloud
subscription, even though OOTH got
banned by Enthropic, I will show you how
to convert to the agents SDK in a
moment. So here is all of the different
crons that I use. in a prompt. I'll drop
it down below. All right, next is
memory. Now, here's the thing. I
basically haven't touched memory and it
has worked great. So many of you have
talked about how bad the memory system
is in OpenCloud, how it constantly
forgets things. And I think it actually
can be solved by one thing. I have
really never had a problem. And I'm just
using the default memory system. I'm not
using QMD. I'm not using any external
services and it works just fine for me.
So, this is all what's built in already
to OpenClaw. But really, here's the key
is two things. One, if you're using
Telegram group topics, you will
instantly have better luck with
OpenClaw's memory because it has to
remember less and it's only remembering
what's relevant to that thread. But
here's the command I suggest you take a
look at frequently. Slash status. Here
we can see the OpenClaw version. Here we
can see the model, the number of tokens
in and out, the cash hit. So 100% cash
hit, which is great. Saves us some
money, and this is the important one,
the context. So I'm at 89%, which is
actually quite full. And I might start
running into memory issues soon here. So
I have two options. I can increase the
rate that messages expire as part of
this Telegram context buildup, or I can
simply just clear it out. And so just
keep a close eye on it. If you notice
your open cloth starts forgetting
things, come here, look how much of your
context is full, and if it is full, you
know, to clear it out. The second thing
is constantly pruning the files that get
loaded into every call. So I have an
automated cron that looks at the files,
looks for any duplicate information,
looks for any prompt drift, basically
looks for opportunities to trim it down.
And I'd say on average, I'm trimming it
by about 10% every other day. But it's
also growing. It's one of those battles
that you're just going to have to
continuously fight. All right, next we
have notification batching. What I
noticed is Telegram became incredibly
noisy and distracting and I wanted a way
to reduce the noise and reduce the
distraction. The problem is if you just
let OpenClaw notify you about everything
going on in that moment, it gets very
distracting. So what we do is we now
batch notifications and they only come
through every so often. So for critical
notifications, it will deliver it
immediately to me. But for high
importance, it does it hourly. So those
are CRM updates, council digests, and
cron failures. Then for medium, it does
it every 3 hours. Routine updates,
non-urgent notifications. And it'll
batch it up. It'll read it all out to me
in Telegram in a really nice summary. So
here's what that look like. All of the
Telegram sends get classified, and then
it is split into three priorities,
batches, and then notifies me. And it
also stores everything in the
notification database. And by the way,
if you're not storing absolutely
everything, which I'll get to in a
moment with logging, you really should
be store everything. All right, a brand
new use case that I started implementing
is financial tracking. I export all
financial transactions from QuickBooks
and I import it into the database and
then I can ask it questions about my
business's finances. Simple natural
language queries. What did I spend the
most money on? which sponsors
represented the most revenue. By the
way, the fact that QuickBooks doesn't do
this is absolutely insane to me. And so,
I simply export it over CSV. I import it
and then it's all there and I can always
query against it. And again, we have
confidentiality rules right here. It
only shares it in DMs or dedicated
financial topic channels. And yeah, very
easy to use. All right. Next, LLM usage
and cost tracking. Very, very important.
Of course, you can go crazy with how
much you use OpenClaw like I do. And you
want a way to see which models are being
used, how often because I have such a
complex taring system of model usage. I
just want to know and maybe approximate
the cost. Open Claw comes with it
natively, but I wrote my own. So, here's
what it looks like. An LLM call gets
hit. It goes through a singular pattern
LLM router. Then, it actually sends it
to the provider. We log it all in two
ways. We have a JSONL backup and then we
also put it in a database. We have a
usage dashboard. We have a cost
estimator, system health with API
failure rates and gateway usage sync.
All of this very easy to query against.
So I can say something like, "Show me my
LLM usage for the last 24 hours." And so
here's what that looks like. We have
Opus 46 715. We have Opus 46 from the
agents SDK since I switched it. You can
see just a ton of different input
tokens, output tokens, and estimated
cost. Obviously, we're using the
subscription across the board, so the
estimated cost is kind of wonky. And I
can even see what part of the apps are
using the most tokens. So, is it cron
jobs? Is it coding? Anything. It's all
tracked in one central place now. And I
can query against it. Next, incredibly,
incredibly important. You want to log
everything. every error, every LLM call,
every time you hit an external service,
you want to log everything because it
just makes it so easy for your open claw
to selfheal. Every morning, the first
thing I do is I say, "Look at the
errors, look at the logs from overnight
and fix any issues." And that's it. It
automatically looks at the logs. It has
full information about what went wrong
and why. And then it goes and fixes it.
And so I have a single pattern event
log.js JS shared across the entire app.
It ingests everything, looks for any
opportunity to log something, logs it in
JSON L, stores it also in a database. We
rotate the log so we don't get this
constantly bloated database. And of
course, I can just query against it. All
right, here's the big one. Anthropic
banned usage of your cloud subscription
OOTH if you're using it outside of an
Anthropic product. But an Enthropic
employee said, "Actually, the agents
SDK, you can still do that." And it
turns out the agents SDK works perfectly
well within OpenClaw. I suspect OpenClaw
will add agents SDK support natively,
but for now, I don't believe they have
it and it's very easy to convert. So now
everything goes through the agents SDK.
I've not had a single O problem since.
And so here's what it looks like. Create
shared anthropic agent SDKJS. Resolve
OOTH token from where it is. Do a smoke
test. Wrap all anthropic calls with auto
retry and logging. Support prompt
caching. All of it runs through the
agent SDK. Now create an LLM router. So
not only are we routing to the agents
SDK, but if we want to use the codeex
SDK from OpenAI, you can do that. Or any
other model that you're using,
centralize it all in LLM router.js.
Okay. Next, here's something I'm still
experimenting with. I have one OpenClaw
instance and it's everything I do for my
personal life and everything I do for my
work life, but how do you keep them
separated? So far, I've been pretty
lucky and there's been no leakage across
different use cases, but it is possible.
We're dealing with non-deterministic
systems. So, we just have a lot of rules
for it. Plus, we have deterministic
systems to look for redaction
opportunities. So, tier confidential
internal versus restricted. So
confidential means DM only me only me it
will only give confidential information
to me. Financial figures CRM contact
details deal values daily notes personal
emails internal so that is my team my
team only nobody external group chats
okay strategic notes council
recommendations tool outputs and assaot
and restricted external only with
explicit approval general knowledge and
anything else. We also define what each
of the emails. So this is my personal
Gmail. This is my work email. This is
our open clause own Gmail account. And
we define all of it. We say what can go
where. And of course we add some
deterministic layers to really prevent
data leakage. So here's what that looks
like. Again, confidential only,
internal, group chat. Okay. And
restricted external. We have the
different types of information for each.
and we look at the context type, decide
what should go where, and it has worked
quite well so far. But again, it's not
going to be perfect, unless you use
deterministic code, and even then, of
course, you're susceptible to bugs. All
right, so I want to actually go back to
logging. So after you log everything,
you get up in the morning and you say,
"Look at the log, see what happened, and
fix it." And that's really all you need
to do. But you also want to save all of
those learnings. You don't want to make
the same mistakes again and again. So
what we do is we have a learnings.md
file. We have an errors.mmd file. We
have a feature request.mmd file. All of
which as we're going we inform openclot
to store things in those files so we
don't make the same mistakes again. We
also have councils that run every night
looking for issues. We have our platform
council and it looks at cron health,
code quality, test coverage, prompt
quality, dependency, storage, skill
integrity, config consistency, CRM data
integrity and more. We have our security
council. We have our innovation scout
looking for new use cases. This is a
cool one. So, every single day it looks
at everything we're doing, goes out on
the web, searches for what other people
are doing, different use cases with Open
Clock, compares all the notes, and comes
up with new ideas. So, here's an
example. Team Calendar Fusion Plus
Travel Intel. And it tells me all about
it. It tells me why it could work. And
same thing here, AI trends auto triage
to a sonic cube meeting follow-through
autopilot. And so it's always given me
new ideas that I can implement. All of
this is being offloaded to cursor agent
CLI, which is what I use, but you can
simply use a sub agent with whatever
model you're using. And of course, if
you have an OpenAI subscription, you can
use the codeex agent CLI. All right.
Next, let's talk about cost savings
because I know this can get very
expensive. So, let me show you some of
the tips and tricks that I've used to
reduce the cost. One, we're using local
embeddings. My MacBook Air is more than
capable of doing the embeddings. Yes,
embeddings are usually extremely
inexpensive, but you know what's better
than inexpensive? Free. So, we use the
Nomic MBEG text on device, zero cost.
Then we have model tiering. We have a
bunch of different models that we're
using and we use the right model at the
right time. Sonnet tends to be my
primary model, Sonnet 4.6, six, which we
have plenty of quota for from the
anthropic subscription. And then it
offloads to other models like Opus 46 if
we need it. Then we also spread out
usage throughout the day, so we're not
using all of our quota in a short
window. We do prompt caching that's
already built in to everything you do.
You don't really have to think about
anything there. So, we do calendar aare
polling and other types of contextaware
polling. So, you don't want to just
constantly pull. You want to look for
signals that tell you when is the best
time to pull something. We do
notification batching and we use cheaper
models, faster models for stuff that
doesn't require Frontier models. All
right, let's talk about backup because
if my computer suddenly caught fire or
it got bricked or stolen or anything, I
can easily back all of this up. So,
here's how we do it. So, we
automatically discover database files.
We encrypt it. We upload it to Google
Drive. We document it. And then of
course we rotate as necessary. We have a
git sync. So every hour it checks any
updates to any of the files, autocommits
the changes and pushes it to GitHub and
gives us a telegram alert. Then if we
need to restore it, we have a whole
markdown file that documents the
restoration process. Download from drive
decrypt, read the manifest, download the
actual code, put it all together, and
it's just done. Easily done. All right.
Two last use cases from Jonah from my
team. These are ones that he uses that
he loves and what I've seen a lot of
other people do as well. He does a lot
of health tracking. So he has an aura
ring, Apple health and wings scale,
which I'm not actually sure what that
is. He ingests all of these things into
a JSON L file, runs claude analysis on
it, daily summary and trend flags plus
coaching. So, it's very easy to set up a
health coach, a very personalized health
coach using this. So, if you have any
type of health tracking device, that's
what you do. Just ingest it and ask
Claude to review it and flag any issues.
All right. And last, this is a really
cool one that you can do with pretty
much any device. I'm not doing it yet,
but I'm definitely going to implement
this. He has a B pendant. It's a little
Amazon device that you wear on your
wrist where you can actually use the
pendant product. You can use Rabbit. You
can use your iPhone. You can do
anything. You basically record notes all
day long. The thing with the B pendant,
it is real time and it is always on. It
basically pulls it. You take voice
notes. You can say, "Oh, remind me of
this thing later." Or it can record a
conversation with somebody and remind
you of things you talked about. Saves it
all in memory. Uses Claude Opus 4.6 for
search. It is confidential DM only. You
can query against all of it and you can
get contextual answers. So, it's kind of
like having your open claw with you at
all times, but it is only one way. The
thing that I really want to be doing is
having a two-way synchronous voice
conversation with my open claw, which I
haven't figured out the best way to do
that yet. If you have any
recommendations, drop them down below.
So, that is it. That is everything I've
learned so far with over 4 and a half
billion tokens used. I am using OpenClaw
all day, all night. I'm absolutely
obsessed. It is really changing the way
I work. The number one thing I've done
with it is made it a full-time employee
on my team. And it just gets better
every single day. I'm still testing
things. I will record another video
certainly, so stick around for that. If
you enjoyed this video, please consider
giving a like and subscribe. and I'll
see you in the next
